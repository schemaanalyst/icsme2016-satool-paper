\section{Related Work}
\begin{enumerate}
\item canonical work
\item our past work
\item related work contrasted with ours
\end{enumerate}

\subsection{Survey of Results}

Kapfhammer et al. compared \textit{SchemaAnalyst} to \textit{DBMonster}
in an experiment using mutation testing over three DBMSs and 25 database 
schemas~\cite{kapfhammer2013search}. The results showed that \textit{SchemaAnalyst} outperformed
\textit{DBMonster} in terms of mutation score and constraint coverage, while remaining competitive
in execution time.

McMinn et al. organized the nine coverage criteria used in \textit{SchemaAnalyst} into an subsumption
hierarchy, and investigated the effectiveness of the criteria in a study across
three DBMSs and 32 database schemas~\cite{mcminn2015effectiveness}.  The results showed mutation
scores as low as $12\%$ for the least stringent criteria, to as high as $96\%$ for the most stringent.

Kinneer et al. conducted a study on the scalability of \textit{SchemaAnalyst}, finding that the tool
scaled well for all realistically sized schemas~\cite{kinneer2015automatically}.

Wright et al. introduced techniques for improving the efficiency of mutation testing for database
schemas using parallelisation~\cite{wright2013efficient}. These techniques were evaluated using two
DBMSs and six database schemas, with one technique resulting in one to ten times performance
improvement for both DBMSs.

Wright et at. used \textit{SchemaAnalyst} to evaluate the influence of ineffective mutants on
database schema mutation analysis in a study that used sixteen database
schemas~\cite{wright2014impact}. Removing the ineffective mutants resulted in efficiency
improvements of up to $33.7\%$.

Chris wrote a thesis about this. Wow, that's a long read~\cite{wright2015mutation}.
