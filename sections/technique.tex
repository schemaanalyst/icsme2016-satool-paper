\section{The \sa~Data Generation Tool}\label{sec:technique}

% Give the basic explanation of how a schema problem can negatively influence a system

An error in the specification of the database schema may result in the corruption of the data state and the disruption
of a supported service.  Even though verifying the accuracy of the database schema is a critical step towards protecting
data integrity, using manually created test data to do so is often expensive and time
consuming~\cite{kapfhammer2013search}.  \sa~uses a search-based approach to generate test data automatically.

% Walk through all of the details in the figure that gives the high-level architecture of the presented tool

Figure~\ref{fig:schemaanalyst} provides a high-level overview of the tool presented in this paper.  After being given a
database schema as input, \sa~uses a coverage criterion to first create a collection of test requirements, or the
rules that the test data must try to fulfill.  For instance, a test requirement for the \texttt{Inventory} schema in
Figure~\ref{fig:schema} might be ``the \texttt{PRIMARY KEY} constraint on line three must be violated''. A coverage
criterion supports systematically generating test requirements.  One example of a coverage criterion is Integrity
Constraint Coverage (ICC)~\cite{mcminn2015effectiveness}. It leads to two test requirements for every integrity
constraint in the schema: one requiring that the constraint is satisfied and another necessitating its violation.
\sa~supports nine coverage criteria, as further explained in~\cite{mcminn2015effectiveness}.

% Further explain the process of test data generation with the presented tool

The presented tool creates test data to satisfy the test requirements using a test data generator; the default test data
generator used by \sa~is based on Korel's Alternating Variable Method (AVM)~\cite{Korel:AVM}. This data generator uses a
fitness function to evaluate how well the test data satisfies the requirements, thereby aiding it in producing test data
that satisfies more of the requirements. For example, \sa~generated the following \texttt{INSERT} statement to violate
the \texttt{PRIMARY KEY} constraint on line three in Figure~\ref{fig:schema}.

% Give the example of the INSERT statement that the presented tool generated

\vspace*{.1in}
\texttt{INSERT INTO} Inventory \texttt{VALUES} (NULL, \textquotesingle\textquotesingle, 0, 0);
\vspace*{.1in}

Since this data instance would set the value for the \texttt{id} field to be \texttt{NULL}, the data violates the
\texttt{PRIMARY KEY} constraint, and should be rejected by the schema.  \sa~encodes this test case as a JUnit test case
by generating Java code to execute the \texttt{INSERT} statement on an installed DBMS, and then assert that the
\texttt{INSERT} statement was rejected by the schema. If this is the case, the test passes.  If the schema allows the
bad data, then the test case fails. JUnit test suites are commonly used by developers, and provide an easy way to use
\sa~on real-world systems.

\sa~also includes features to evaluate the quality of the generated test data. The coverage is the percentage of the
requirements satisfied by the test data.  Test data quality can also be measured using the provided mutation testing
tools. When executed in mutation testing mode, \sa~will generate mutant database schemas and compare the behavior of the
test data on the original and mutant schemas. \sa~includes 14 different mutation operators that can be used to assess
test suite quality~\cite{wright2015mutation}.

\input{figures/sa-new}
